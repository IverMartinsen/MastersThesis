{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "169o-UWdz1SYb_zeCputD7idX1RMV5kF5",
      "authorship_tag": "ABX9TyNoHE/f6Huljds31k3WUXtW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IverMartinsen/MastersThesis/blob/main/Notebooks/random_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkcx6ybNeSNw"
      },
      "source": [
        "This notebook show a random search for hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTQTKYTekyXB",
        "outputId": "62f8e6b4-9727-4e36-fb86-d92830ba1811"
      },
      "source": [
        "!pip install -q -U keras-tuner\n",
        "\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU\n",
        "from tensorflow.keras.layers import MaxPool2D, Dropout, Dense, Flatten\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "import tensorflow as tf\n",
        "import kerastuner as kt\n",
        "import numpy as np\n",
        "\n",
        "def build_model(hp):\n",
        "    \n",
        "    L2 = tf.keras.regularizers.L2(\n",
        "        l2=hp.Float(\"l2_norm\", 1e-5, 1e-1, sampling=\"log\"))\n",
        "    \n",
        "    inputs = Input(shape=(128, 128, 1))\n",
        "\n",
        "    x = Rescaling(1./255)(inputs)\n",
        "\n",
        "    filter_set = [8, 16, 24, 32, 48, 64, 96, 128]\n",
        "\n",
        "    for i in range(hp.Int(\"num_conv_blocks\", 3, 5)):\n",
        "        \n",
        "        filters = hp.Choice(\"conv_filters_\" + str(i+1), filter_set[i:i+4])\n",
        "\n",
        "        for j in range(hp.Int(\"block_size_\" + str(i+1), 1, 2)):\n",
        "            \n",
        "            x = Conv2D(filters, 3, padding='same', kernel_regularizer=L2)(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = ReLU()(x)\n",
        "        \n",
        "        x = MaxPool2D()(x)\n",
        "        \n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    for i in range(hp.Int(\"dense_blocks\", 1, 2)):\n",
        "        \n",
        "        x = Dense(\n",
        "            hp.Int(\"dense_block_\" + str(i+1), 8, 128, 8), \n",
        "            activation='relu', \n",
        "            kernel_regularizer=L2\n",
        "            )(x)\n",
        "        \n",
        "        if i == 0:\n",
        "            x = Dropout(hp.Float(\"dropout\", 0, 0.5, 0.1))(x)\n",
        "  \n",
        "    outputs = Dense(1, activation='sigmoid', kernel_regularizer=L2)(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            hp.Float(\"learning_rate\", 1e-4, 1e-1, sampling=\"log\")),\n",
        "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# import training and validation data\n",
        "path = '/content/drive/MyDrive/Masteroppgave/Data/Torskeotolitter/standard_convex'\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    path,\n",
        "    label_mode='binary',\n",
        "    validation_split=0.4,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(128, 128),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32)\n",
        "\n",
        "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    path,\n",
        "    label_mode='binary',\n",
        "    validation_split=0.4,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(128, 128),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32)\n",
        "\n",
        "# define parameter tuner instance\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_binary_accuracy\",\n",
        "    max_trials=100, \n",
        "    project_name='random_search_4')\n",
        "\n",
        "# search for parameters\n",
        "tuner.search(\n",
        "    train_ds, \n",
        "    epochs=1000, \n",
        "    validation_data=valid_ds,\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        patience=20, restore_best_weights=True)])\n",
        "\n",
        "# save best model\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "model.save('/content/drive/MyDrive/Masteroppgave/best_convex_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 100 Complete [00h 01m 54s]\n",
            "val_binary_accuracy: 0.561475396156311\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.8319672346115112\n",
            "Total elapsed time: 03h 13m 35s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Masteroppgave/best_convex_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}