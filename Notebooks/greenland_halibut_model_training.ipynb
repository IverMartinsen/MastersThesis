{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "greenland_halibut_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LP63ak8vhdwS5580kEVXd-I0hEv3qUYa",
      "authorship_tag": "ABX9TyO2qx4cN6Zufb3L0565MKjy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IverMartinsen/MastersThesis/blob/main/Notebooks/greenland_halibut_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D-ehcYxcE8h"
      },
      "source": [
        "###This notebook shows the training of three models on the Greenland halibut data.\n",
        "----------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzclnMaHcZNs"
      },
      "source": [
        "Clone repository to gain access to modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fme2LBMkwJp"
      },
      "source": [
        "!git clone https://github.com/IverMartinsen/MastersThesis.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xQKXcr-WpUR"
      },
      "source": [
        "Import modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpD5OSCrKTZ"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/MastersThesis/Python')\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from modules.stratified_idxs import stratified_idxs\n",
        "from modules.losses import MeanSquaredErrorKLD\n",
        "from scipy.optimize import minimize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRL778d0X9-4"
      },
      "source": [
        "Load features, i.e. age, sex and length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8-XeTupr-Jc"
      },
      "source": [
        "# Load dataframe of features\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataframe.csv')\n",
        "\n",
        "# Locate data points with complete and incomplete set of features\n",
        "notna = np.all(np.array(df.notna()), axis = 1)\n",
        "isna = np.any(np.array(df.isna()), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du3wHKN-ZAh3"
      },
      "source": [
        "Load images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O110AQ2_ZBvs"
      },
      "source": [
        "# Only use images with complete set of features\n",
        "images = np.load('/content/drive/MyDrive/images256.npy', fix_imports=True)\n",
        "image_size = images.shape[1:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2XDE5gyUSM8"
      },
      "source": [
        "Create baseline data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUL89ciyUTYK"
      },
      "source": [
        "num_baselines = 50\n",
        "baseline_images = tf.constant(0, shape=(num_baselines, ) + image_size + (3, ))\n",
        "baseline_labels = tf.constant(0, shape=(num_baselines,))\n",
        "baseline_sexes = tf.constant(np.random.choice(['male', 'female'], num_baselines))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syg_q8s3mgHl"
      },
      "source": [
        "Create subsets for training, validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54XSqpHBYx6L"
      },
      "source": [
        "# Create stratified indices for selecting datasets for training etc.\n",
        "train_idx, valid_idx, test_idx = stratified_idxs(df['age'].iloc[notna], (0.8, 0.1, 0.1), seed=123)\n",
        "\n",
        "# Create utility function for creating datasets compatible with tensorflow\n",
        "set_from_idx = lambda idx : (tf.convert_to_tensor(df['sex'].iloc[notna].iloc[idx]), images[notna][idx])\n",
        "\n",
        "# Create stratified subsets for training, validation and testing\n",
        "y_tr = df['age'].iloc[notna].iloc[train_idx]\n",
        "y_va = df['age'].iloc[notna].iloc[valid_idx]\n",
        "y_te = df['age'].iloc[notna].iloc[test_idx]\n",
        "\n",
        "f_tr = df['filename'].iloc[notna].iloc[train_idx]\n",
        "f_va = df['filename'].iloc[notna].iloc[valid_idx]\n",
        "f_te = df['filename'].iloc[notna].iloc[test_idx]\n",
        "\n",
        "ds_train = tf.data.Dataset.from_tensor_slices(((tf.convert_to_tensor(df['sex'].iloc[notna].iloc[train_idx]), images[notna][train_idx]), y_tr)).shuffle(len(train_idx)).batch(32)\n",
        "ds_unknown = tf.data.Dataset.from_tensor_slices(((tf.constant('unknown', shape = sum(isna)), images[isna]), df['age'].iloc[isna])).shuffle(sum(isna)).batch(32)\n",
        "ds_valid = tf.data.Dataset.from_tensor_slices((set_from_idx(valid_idx), y_va)).batch(32)\n",
        "ds_test = tf.data.Dataset.from_tensor_slices((set_from_idx(test_idx), y_te)).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS-O4LUIoAya"
      },
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFcyodGBCcwV"
      },
      "source": [
        "# Create layer for mapping categorical labels to int\n",
        "Index = tf.keras.layers.StringLookup()\n",
        "# Fit index layer on training data\n",
        "Index.adapt(tf.constant(df['sex']))\n",
        "\n",
        "# Create layer for one-hot-encoding the categorical labels\n",
        "Encoding = tf.keras.layers.CategoryEncoding(num_tokens=Index.vocabulary_size(), output_mode='one_hot')\n",
        "\n",
        "# Define pretrained base model without classification head. Use global average pooling on output.\n",
        "base_model = tf.keras.applications.Xception(\n",
        "    input_shape=image_size + (3, ), \n",
        "    include_top=False,\n",
        "    pooling='avg')\n",
        "\n",
        "# Define full model. Note that by setting training=False in the base model\n",
        "# we always run the model in inference mode. \n",
        "img_input = tf.keras.layers.Input(image_size + (3, ))\n",
        "cat_input = tf.keras.Input(shape=(1,), name='gender', dtype='string')\n",
        "\n",
        "gender = Encoding(Index(cat_input))\n",
        "\n",
        "# First we process the images\n",
        "x = tf.keras.applications.xception.preprocess_input(img_input)\n",
        "x = tf.keras.layers.RandomTranslation(0, 0.1)(x)\n",
        "x = tf.keras.layers.RandomRotation(0.1, fill_mode='constant')(x)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "x = tf.keras.layers.Dense(3, 'relu')(x)\n",
        "# Then we us multiplication to get the gender conditional age predictions \n",
        "outputs = tf.keras.layers.Dot(axes=1)([x, gender])\n",
        "# Finally we concatenate the age prediction with the one-hot sex matrix\n",
        "model = tf.keras.models.Model([cat_input, img_input], outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGi4bptbqrj0"
      },
      "source": [
        "Compile and fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_SJvLBoH_pM"
      },
      "source": [
        "# Compile model using custom loss function\n",
        "model.compile(tf.keras.optimizers.Adam(0.0005), tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "# Apply early stopping\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
        "\n",
        "# Fit model\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=100,\n",
        "    validation_data=ds_valid,\n",
        "    callbacks = callbacks\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4etQgMNreT5"
      },
      "source": [
        "Predict age by image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oiNk3zOrgPT"
      },
      "source": [
        "y1 = model.predict(ds_test)[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuh-wccnrPwK"
      },
      "source": [
        "Predict age by length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kfdRL4LrUuS"
      },
      "source": [
        "# Define loss function to be minimized as function of parameters\n",
        "loss_by_length = lambda params: tf.reduce_mean(\n",
        "    (y_tr - params[0] + tf.math.log(1 - df['length'].iloc[train_idx]/params[1])/params[2])**2).numpy()\n",
        "\n",
        "# Find optimal set of parameters\n",
        "params = minimize(loss_by_length, (1, 10000, 1)).x\n",
        "\n",
        "# Define function that takes length as input and returns age\n",
        "age_by_length = lambda params: lambda length: tf.cast(params[0] - tf.math.log(1 - length/params[1])/params[2], tf.float32).numpy()\n",
        "\n",
        "# Predict age by length of test set\n",
        "y2 = age_by_length(params)(df['length'].iloc[test_idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAUwpPGbsZEm"
      },
      "source": [
        "Predict age by a weighted sum of y1 and y2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxRXw6q7sf9d"
      },
      "source": [
        "# Column of ones with length equal to number of training samples\n",
        "z0 = tf.constant(1, shape=train_idx.shape, dtype=tf.float32)\n",
        "# Age of training samples predicted by the model\n",
        "z1 = model.predict(set_from_idx(train_idx))[:, 0]\n",
        "# Age of training samples predicted by length\n",
        "z2 = age_by_length(params)(df['length'].iloc[train_idx])\n",
        "# Design matrix based on training samples\n",
        "z = tf.stack([z0, z1, z2], axis = 1)\n",
        "# Weights of the linear model\n",
        "w = tf.matmul(\n",
        "    tf.matmul(\n",
        "        tf.linalg.inv(\n",
        "            tf.linalg.matmul(\n",
        "                tf.transpose(z), z)), tf.transpose(z)), tf.cast(tf.reshape(y_tr, (-1, 1)), tf.float32))\n",
        "\n",
        "# Column of ones with length equal to the number of test samples\n",
        "y0 = tf.constant(1, shape=y1.shape, dtype=tf.float32)\n",
        "# Age predictions for the test set\n",
        "y3 = tf.matmul(tf.stack((y0, y1, y2), axis=1), w).numpy().reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY7a_tBoXDpG"
      },
      "source": [
        "Print loss and accuracy for each sex on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoYxchIa7oqZ"
      },
      "source": [
        "names = ('Deep Learning', 'Length', 'Both')\n",
        "\n",
        "# Filename for summary statistics\n",
        "filename = '/content/drive/Othercomputers/Min bærbare datamaskin/UiT/output.txt'\n",
        "\n",
        "# Write summary statistics to file\n",
        "with open(filename, 'w') as f:\n",
        "    for j, predictions in enumerate((y1, y2, y3)):\n",
        "        print(names[j] + '\\n', file=f)\n",
        "\n",
        "        print(f'Number of samples: {len(y_te)}', file=f)\n",
        "        print(f'Loss: {tf.keras.losses.mean_squared_error(y_te, predictions).numpy():.4f}', file=f)\n",
        "\n",
        "        for i in range(3):\n",
        "            print(f'{i}-off accuracy: {np.sum(np.abs(predictions.round() - y_te) <= i)*100 / len(y_te):.2f} %', file=f)\n",
        "        print('----------------------------------------------', file=f)\n",
        "\n",
        "        for sex in ['male', 'female']:\n",
        "            idx = np.where(df.iloc[test_idx]['sex'] == sex)[0]\n",
        "\n",
        "            print(f'Number of {sex} samples: {len(idx)}', file=f)\n",
        "            print(f'{sex} loss: {tf.keras.losses.mean_squared_error(y_te.iloc[idx], predictions[idx]).numpy():.4f}', file=f)\n",
        "\n",
        "            for i in range(3):\n",
        "                print(f'{i}-off accuracy: {np.sum(np.abs(predictions.round()[idx] - y_te.iloc[idx]) <= i)*100 / len(y_te.iloc[idx]):.2f} %', file=f)\n",
        "            print('----------------------------------------------', file=f)\n",
        "        print('\\n', file=f)\n",
        "\n",
        "# Print content of file\n",
        "with open(filename, 'r') as f:\n",
        "    print(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXc7HOxdgCQh"
      },
      "source": [
        "Save predictions to csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwZOSGUP9rUb"
      },
      "source": [
        "# Save design matrix for linear regression analysis\n",
        "pd.DataFrame({'y': y_tr, 'x1': z1, 'x2': z2}).to_csv('design_matrix.csv', index=False)\n",
        "\n",
        "# Save predictions of test data\n",
        "pd.DataFrame({\n",
        "    'filenames': f_te, \n",
        "    'true_age': y_te, \n",
        "    'pred_age_deep': y1.round().astype(int),\n",
        "    'pred_age_length': y2.round().astype(int), \n",
        "    'pred_age_both': y3.round().astype(int),\n",
        "    'sex': df.iloc[test_idx]['sex']}).to_csv('/content/drive/Othercomputers/Min bærbare datamaskin/UiT/predictions.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKNdd5PabXmV"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbn9bUTLbYxt"
      },
      "source": [
        "model.save('/content/drive/Othercomputers/Min bærbare datamaskin/UiT/Forberedende forsøk/testrun8_exception')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}