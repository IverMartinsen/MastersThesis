{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "compute_gradients.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xRf3qUt_n3fnfLYi4bRJcTjQ1I2Sp8AN",
      "authorship_tag": "ABX9TyNuarfnwqiSqyu7Ru140Uz1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IverMartinsen/MastersThesis/blob/main/Notebooks/cod_pixel_relevance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8uLlPNoag6C"
      },
      "source": [
        "##This notebook shows feature relevance methods applied on cod otoliths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwFqeQk4ynYG"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M47Z1aZ0ypvG"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/src/Python/modules')\n",
        "\n",
        "import tensorflow as tf\n",
        "from modules.imageloader import load_images\n",
        "from modules.analysis.utils import compute_gradients\n",
        "from modules.analysis.integrated_gradients import integrated_gradients, ig_error\n",
        "from modules.analysis.guided_backpropagation import build_gb_model_nonseq\n",
        "from modules.image_tools import normalize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLzLyrAx8ro"
      },
      "source": [
        "Import images and set variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dRfjesTxyMv"
      },
      "source": [
        "img_size = (128, 128)\n",
        "img_shape = img_size + (3,)\n",
        "initial_epochs = 100\n",
        "batch_size = 32\n",
        "path_to_files = r'/content/drive/MyDrive/Data/Torskeotolitter/standard'\n",
        "\n",
        "sets = load_images(\n",
        "    path_to_files, img_size, splits=1, seed=321, mode='RGB')\n",
        "\n",
        "ds = sets[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrMOdqH1yAm1"
      },
      "source": [
        "Load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD5ZBR4NyCy4"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Artikkel om torskeotolitter/Saved models/Xception_2.6.0')\n",
        "\n",
        "base_model = tf.keras.applications.Xception(\n",
        "    input_shape=img_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        "    )\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "gb_base_model = build_gb_model_nonseq(base_model, tf.keras.layers.Activation)\n",
        "\n",
        "inputs = tf.keras.Input(img_shape)\n",
        "x = tf.keras.applications.xception.preprocess_input(inputs)\n",
        "x = gb_base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(3, 'sigmoid')(x)\n",
        "\n",
        "gb_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "gb_model.compile(    \n",
        "    tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics='accuracy')\n",
        "\n",
        "# Load the weights from trained model\n",
        "gb_model.set_weights(model.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kirj418hykNX"
      },
      "source": [
        "Compute integrated gradients for all images from target class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmB03o-Py7ak"
      },
      "source": [
        "target_class_idx = 0\n",
        "\n",
        "m_steps = 100\n",
        "\n",
        "baseline = np.zeros_like(ds['images'][0])\n",
        "\n",
        "# store target class indices\n",
        "idxs = np.where(\n",
        "    np.argmax(model.predict(ds['images']), axis = 1) == target_class_idx)\n",
        "\n",
        "# count number of images from target class\n",
        "num_images = np.shape(idxs)[-1]\n",
        "\n",
        "# TensorArray's for storage of gradients, errors and images\n",
        "ig_gradients = tf.TensorArray(tf.float32, size=9)\n",
        "ig_errors = tf.TensorArray(tf.float32, size=9)\n",
        "\n",
        "for i, image in enumerate(ds['images'][idxs][:9]):\n",
        "    \n",
        "    ig = integrated_gradients(\n",
        "            gb_model, baseline, image, target_class_idx, m_steps, batch_size)\n",
        "\n",
        "    ig_gradients = ig_gradients.write(i, ig)\n",
        "    \n",
        "    ig_errors = ig_errors.write(i, ig_error(\n",
        "        model, baseline, image, ig, target_class_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw1FM2oa_B1y"
      },
      "source": [
        "Display and save figure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Prtbtw1mpB"
      },
      "source": [
        "destination = '/content/drive/MyDrive/Artikkel om torskeotolitter/cc2/'\n",
        "\n",
        "# display a random selection of heatmaps and save figure\n",
        "fig, ax = plt.subplots(3, 3, facecolor='black')\n",
        "for i, ax in enumerate(ax.flatten()):\n",
        "    ax.imshow(\n",
        "        normalize(\n",
        "            tf.abs(\n",
        "                tf.reduce_sum(ig_gradients.stack()[i], axis = 2))), \n",
        "              plt.cm.afmhot, vmin = 0, vmax = 1)\n",
        "    #ax.imshow(tf.reduce_sum(ds['images'][idxs][i], axis = 2), 'gray', alpha = 0.3)\n",
        "    ax.axis('off')\n",
        "    ax.patch.set_facecolor('black')\n",
        "plt.subplots_adjust(wspace=-0.5, hspace=0)\n",
        "\n",
        "plt.savefig(\n",
        "    destination + 'cc_selection_gb_ig_combined.jpg', \n",
        "    dpi=300, \n",
        "    bbox_inches=\"tight\", \n",
        "    pad_inches=0, \n",
        "    facecolor='black')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uz4rhPuAsbb"
      },
      "source": [
        "Save filenames and errors to txt files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo5_jiCE1qn4"
      },
      "source": [
        "# list all filenames belonging to target class for storage\n",
        "filenames = np.array(ds['filenames'])[idxs]\n",
        "\n",
        "# write filenames to text file\n",
        "with open(destination + 'cc_filenames.txt', 'w') as f:\n",
        "    for item in filenames[:9]:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "# write errors to text file\n",
        "with open(destination + 'cc_errors.txt', 'w') as f:\n",
        "    for item in ig_errors.stack():\n",
        "        f.write(\"%s\\n\" % float(item.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLJ_m5yX10TN"
      },
      "source": [
        "Compute gradients by guided backpropagation for all images classified as target class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvwUCVaM10DO"
      },
      "source": [
        "# compute gradients of inputs wrt outputs\n",
        "gb_gradients = compute_gradients( \n",
        "    tf.convert_to_tensor(ds['images'][idxs][:9]),\n",
        "    gb_model,\n",
        "    target_class_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btdw0i1x15Sj"
      },
      "source": [
        "Display and save figure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650DDFDC1xWx"
      },
      "source": [
        "# display a random selection of heatmaps and save figure\n",
        "fig, ax = plt.subplots(3, 3, facecolor='black')\n",
        "for i, ax in enumerate(ax.flatten()):\n",
        "    ax.imshow(\n",
        "        normalize(\n",
        "            tf.abs(tf.reduce_sum(\n",
        "                gb_gradients[i], axis = 2))), \n",
        "              plt.cm.hot, vmin = 0, vmax = 1)\n",
        "    ax.imshow(tf.reduce_sum(ds['images'][idxs][i], axis = 2), 'gray', alpha = 0.3)\n",
        "    ax.axis('off')\n",
        "    ax.patch.set_facecolor('black')\n",
        "plt.subplots_adjust(wspace=-0.5, hspace=0)\n",
        "\n",
        "\n",
        "plt.savefig(\n",
        "    destination + 'cc_selection_gb_overlay.jpg', \n",
        "    dpi=300, \n",
        "    bbox_inches=\"tight\", \n",
        "    pad_inches=0, \n",
        "    facecolor='black')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgliXrxgEhms"
      },
      "source": [
        "Compute ordinary gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe5T9rBnEj30"
      },
      "source": [
        "# compute gradients of inputs wrt outputs\n",
        "vanilla_gradients = compute_gradients( \n",
        "    tf.convert_to_tensor(ds['images'][idxs][:9]),\n",
        "    model,\n",
        "    target_class_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NOKhYwv18Bn"
      },
      "source": [
        "# display a random selection of heatmaps and save figure\n",
        "fig, ax = plt.subplots(3, 3, facecolor='black')\n",
        "for i, ax in enumerate(ax.flatten()):\n",
        "    ax.imshow(\n",
        "        normalize(\n",
        "            tf.abs(tf.reduce_sum(\n",
        "                vanilla_gradients[i], axis = 2))), \n",
        "              plt.cm.hot, vmin = 0, vmax = 1)\n",
        "    #ax.imshow(tf.reduce_sum(ds['images'][idxs][i], axis = 2), 'gray', alpha = 0.3)\n",
        "    ax.axis('off')\n",
        "    ax.patch.set_facecolor('black')\n",
        "plt.subplots_adjust(wspace=-0.5, hspace=0)\n",
        "\n",
        "plt.savefig(\n",
        "    destination + 'neac_selection_vanilla.jpg', \n",
        "    dpi=300, \n",
        "    bbox_inches=\"tight\", \n",
        "    pad_inches=0, \n",
        "    facecolor='black')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lm5hE8WFlYr"
      },
      "source": [
        "Compare visualization methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfRPn_b_FqZH"
      },
      "source": [
        "# display a random selection of heatmaps and save figure\n",
        "fig, ax = plt.subplots(3, 4, facecolor='black')\n",
        "\n",
        "for i, axes in enumerate(ax):\n",
        "\n",
        "    axes[0].imshow(\n",
        "        tf.reduce_sum(ds['images'][idxs][i], axis = 2), 'gray')\n",
        "    axes[0].axis('off')\n",
        "    axes[0].patch.set_facecolor('black')\n",
        "\n",
        "\n",
        "    axes[1].imshow(\n",
        "        normalize(\n",
        "            tf.abs(tf.reduce_sum(\n",
        "                vanilla_gradients[i], axis = 2)))*normalize(tf.reduce_sum(ds['images'][idxs][i], axis = 2)), \n",
        "              plt.cm.hot, vmin = 0, vmax = 1)\n",
        "    axes[1].axis('off')\n",
        "    axes[1].patch.set_facecolor('black')\n",
        "\n",
        "\n",
        "    axes[2].imshow(\n",
        "        normalize(\n",
        "            tf.abs(tf.reduce_sum(\n",
        "                gb_gradients[i], axis = 2)))*normalize(tf.reduce_sum(ds['images'][idxs][i], axis = 2)), \n",
        "              plt.cm.hot, vmin = 0, vmax = 1)    \n",
        "    axes[2].axis('off')\n",
        "    axes[2].patch.set_facecolor('black')\n",
        "\n",
        "    axes[3].imshow(\n",
        "        normalize(\n",
        "            tf.abs(\n",
        "                tf.reduce_sum(ig_gradients.stack()[i], axis = 2))), \n",
        "              plt.cm.afmhot, vmin = 0, vmax = 1)\n",
        "\n",
        "    axes[3].axis('off')\n",
        "    axes[3].patch.set_facecolor('black')\n",
        "\n",
        "plt.subplots_adjust(wspace=-0.3, hspace=0)\n",
        "\n",
        "plt.savefig(\n",
        "    destination + 'cc_comparison.jpg', \n",
        "    dpi=300, \n",
        "    bbox_inches=\"tight\", \n",
        "    pad_inches=0, \n",
        "    facecolor='black')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}