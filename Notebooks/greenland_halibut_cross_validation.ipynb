{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kfold_trial_sript_greenland_halibuts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WZJhykQx6FOJeY7SVrwODG__gB4IzLgy",
      "authorship_tag": "ABX9TyMDuOEaA8F2MA1Cs0eYN+cP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IverMartinsen/MastersThesis/blob/main/Notebooks/greenland_halibut_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTR_hPMlbEeG"
      },
      "source": [
        "###This note book shows the k*l-fold cross validation procedure conducted on the Greenland halibut training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2-hlzkqbYOR"
      },
      "source": [
        "Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "samSyDWDViqM"
      },
      "source": [
        "!git clone https://github.com/IverMartinsen/MastersThesis.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xQKXcr-WpUR"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpD5OSCrKTZ"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/MastersThesis/Python')\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from modules.stratified_idxs import stratified_idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRL778d0X9-4"
      },
      "source": [
        "Load features, i.e. age, sex and length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8-XeTupr-Jc"
      },
      "source": [
        "# Load dataframe of features\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataframe.csv')\n",
        "\n",
        "# Locate data points with complete set of features\n",
        "notna = np.all(np.array(df.notna()), axis = 1)\n",
        "\n",
        "# Drop data with incomplete set of features\n",
        "df = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du3wHKN-ZAh3"
      },
      "source": [
        "Load images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O110AQ2_ZBvs"
      },
      "source": [
        "# Only use images with complete set of features\n",
        "images = np.load('/content/drive/MyDrive/images256.npy')[notna]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syg_q8s3mgHl"
      },
      "source": [
        "Create subsets for training, validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54XSqpHBYx6L"
      },
      "source": [
        "# Create stratified indices for selecting datasets for training etc.\n",
        "strata_idxs = stratified_idxs(df['age'], 10, seed=123)\n",
        "\n",
        "# Define utility functions for creating tensorflow compatible datasets\n",
        "def set_from_idx(idx, training=False):\n",
        "    if training:\n",
        "        return tf.data.Dataset.from_tensor_slices(\n",
        "            ((tf.convert_to_tensor(df['sex'].iloc[idx]), images[idx]), df['age'].iloc[idx])).shuffle(len(idx)).batch(batch_size)\n",
        "    else:\n",
        "        return tf.data.Dataset.from_tensor_slices(\n",
        "            ((tf.convert_to_tensor(df['sex'].iloc[idx]), images[idx]), df['age'].iloc[idx])).batch(batch_size)\n",
        "\n",
        "def mat_from_idx(idx, y=None):\n",
        "    if y is None:\n",
        "        return tf.stack((df['length'].iloc[idx], df['length'].iloc[idx]*(df['sex'].iloc[idx] == 'male')), axis=1)\n",
        "    else:\n",
        "        return tf.stack((df['length'].iloc[idx], df['length'].iloc[idx]*(df['sex'].iloc[idx] == 'male'), y), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS-O4LUIoAya"
      },
      "source": [
        "Define function for building and compiling model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFcyodGBCcwV"
      },
      "source": [
        "def build_model():\n",
        "\n",
        "    # Create layer for mapping categorical labels to int\n",
        "    Index = tf.keras.layers.StringLookup()\n",
        "    # Fit index layer on training data\n",
        "    Index.adapt(tf.constant(df['sex']))\n",
        "\n",
        "    # Create layer for one-hot-encoding the categorical labels\n",
        "    Encoding = tf.keras.layers.CategoryEncoding(num_tokens=Index.vocabulary_size(), output_mode='one_hot')\n",
        "\n",
        "    # Define pretrained base model without classification head. Use global average pooling on output.\n",
        "    base_model = tf.keras.applications.Xception(\n",
        "        input_shape=image_size + (3, ), \n",
        "        include_top=False,\n",
        "        pooling='avg')\n",
        "\n",
        "    # Define full model. Note that by setting training=False in the base model\n",
        "    # we always run the model in inference mode. \n",
        "    img_input = tf.keras.layers.Input(image_size + (3, ))\n",
        "    cat_input = tf.keras.Input(shape=(1,), name='gender', dtype='string')\n",
        "\n",
        "    gender = Encoding(Index(cat_input))\n",
        "\n",
        "    # First we process the images\n",
        "    x = tf.keras.applications.xception.preprocess_input(img_input)\n",
        "    x = tf.keras.layers.RandomTranslation(0, 0.1)(x)\n",
        "    x = tf.keras.layers.RandomRotation(0.1, fill_mode='constant')(x)\n",
        "    x = base_model(x, training=False)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "    x = tf.keras.layers.Dense(3, 'relu')(x)\n",
        "    # Then we us multiplication to get the gender conditional age predictions \n",
        "    outputs = tf.keras.layers.Dot(axes=1)([x, gender])\n",
        "    # Finally we concatenate the age prediction with the one-hot sex matrix\n",
        "    model = tf.keras.models.Model([cat_input, img_input], outputs)\n",
        "\n",
        "    # Compile model using custom loss function\n",
        "    model.compile(tf.keras.optimizers.Adam(0.00046625), tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_linear_model(num_predictors):\n",
        "    inputs = tf.keras.layers.Input(shape=(num_predictors, ))\n",
        "    outputs = tf.keras.layers.Dense(1)(inputs)\n",
        "    linear_model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    linear_model.compile(tf.keras.optimizers.Adam(1e-3), tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "    return linear_model    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDGgPaUxW_2Q"
      },
      "source": [
        "Set variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoz-T-dHW7pI"
      },
      "source": [
        "image_size = images.shape[1:3]\n",
        "max_epochs = 100\n",
        "batch_size = 32\n",
        "model = None\n",
        "linear_model = None\n",
        "patience = 20\n",
        "\n",
        "summary = pd.DataFrame(index=range(10), columns=['loss1', 'loss2', 'loss3'])\n",
        "results = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGi4bptbqrj0"
      },
      "source": [
        "Execute validation procedure and save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_SJvLBoH_pM"
      },
      "source": [
        "for i in range(len(strata_idxs)):\n",
        "\n",
        "    test_idx = strata_idxs[i]\n",
        "    \n",
        "    if i+1 < len(strata_idxs):\n",
        "        valid_idx = strata_idxs[i+1]\n",
        "        train_idx = np.concatenate(np.delete(strata_idxs, [i, i+1]))\n",
        "    else:\n",
        "        valid_idx = strata_idxs[0]\n",
        "        train_idx = np.concatenate(np.delete(strata_idxs, [i, 0]))\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "        \n",
        "    del model\n",
        "    del linear_model\n",
        "\n",
        "    print(f'\\nStarting trial {i+1}\\n')\n",
        "\n",
        "    # Predict age by image\n",
        "    model = build_model()\n",
        "\n",
        "    callbacks = tf.keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True)\n",
        "\n",
        "    model.fit(\n",
        "        set_from_idx(train_idx, training=True),\n",
        "        epochs=max_epochs,\n",
        "        validation_data=set_from_idx(valid_idx),\n",
        "        callbacks = callbacks\n",
        "        )\n",
        "    \n",
        "    y1 = model.predict(set_from_idx(test_idx)).flatten()\n",
        "    \n",
        "    summary['loss1'].iloc[i] = model.evaluate(set_from_idx(test_idx))\n",
        "\n",
        "    # Predict age by length\n",
        "    linear_model = build_linear_model(num_predictors=2)\n",
        "\n",
        "    callbacks = tf.keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True)\n",
        "    \n",
        "    linear_model.fit(\n",
        "        mat_from_idx(train_idx),\n",
        "        df['age'].iloc[train_idx],\n",
        "        epochs=max_epochs,\n",
        "        validation_data=(mat_from_idx(valid_idx), df['age'].iloc[valid_idx]),\n",
        "        callbacks=callbacks\n",
        "        )\n",
        "    \n",
        "    y2 = linear_model.predict(mat_from_idx(test_idx)).flatten()\n",
        "    summary['loss2'].iloc[i] = linear_model.evaluate(mat_from_idx(test_idx), df['age'].iloc[test_idx])\n",
        "\n",
        "    # Predict age by combining models\n",
        "    linear_model = build_linear_model(num_predictors=3)\n",
        "\n",
        "    callbacks = tf.keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True)\n",
        "\n",
        "    linear_model.fit(\n",
        "        mat_from_idx(train_idx, y=model.predict(set_from_idx(train_idx)).flatten()),\n",
        "        df['age'].iloc[train_idx],\n",
        "        epochs=max_epochs,\n",
        "        validation_data=(mat_from_idx(valid_idx, y=model.predict(set_from_idx(valid_idx)).flatten()), df['age'].iloc[valid_idx]),\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    y3 = linear_model.predict(mat_from_idx(test_idx, y=y1)).flatten()\n",
        "    summary['loss3'].iloc[i] = linear_model.evaluate(mat_from_idx(test_idx, y=y1), df['age'].iloc[test_idx])\n",
        "\n",
        "    # Store results\n",
        "    result = pd.DataFrame(\n",
        "        {'filename': df['filename'].iloc[test_idx],\n",
        "         'age': df['age'].iloc[test_idx],\n",
        "         'length': df['length'].iloc[test_idx],\n",
        "         'sex': df['sex'].iloc[test_idx],\n",
        "         'y1': y1,\n",
        "         'y2': y2,\n",
        "         'y3': y3}\n",
        "    )\n",
        "\n",
        "    if i == 0:\n",
        "        results = result\n",
        "    else:\n",
        "        results = pd.merge(results, result, how='outer')\n",
        "\n",
        "# Save results to file\n",
        "summary.to_csv('/content/drive/MyDrive/summary.csv')\n",
        "results.to_csv('/content/drive/MyDrive/results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}